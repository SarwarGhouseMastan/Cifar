# -*- coding: utf-8 -*-
"""cifar_10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QBF1-Ftd7Nkg2XYMeLh8J2zZLLd0Tf7H
"""

# importing the important libararies

import tensorflow as tf

tf.keras.datasets.cifar10.load_data()

# importing the important libararies
import tensorflow as tf
# from tensflow.keras.datasets import cifar10
from tensorflow.keras.layers import Conv2D , MaxPool2D ,Flatten , Dense , Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical

import matplotlib.pyplot as plt

cifar10 = tf.keras.datasets.cifar10.load_data()

#loading the dataset
(x_train , y_train) , (x_test , y_test) = cifar10

x_train.shape

# (number of images , rows , col , dimension)

x_test.shape

y_train.shape

y_test.shape

classes = ["airplane" , "automobile" , "bird" , "cat" , "deer" , "dog" , "frog" , " horse" , "ship" , "truck"]

plt.imshow(x_train[0])

class_number = 32
plt.imshow(x_train[class_number])

# normalising the data

X_train , X_test = x_train/255.0 , x_test/255.0

# 1 model building
# 2 compilation
# 3 model training(fit)

# model creation
model = Sequential()

# 1st Conv layer
model.add(Conv2D(36,3, activation = "relu" , kernel_initializer ="he_uniform"))
model.add(MaxPool2D())

# 2nd Conv layer
model.add(Conv2D(72,3, activation = "relu" , kernel_initializer ="he_uniform"))
model.add(MaxPool2D())


# 3rd Conv layer
model.add(Conv2D(72*2,3, activation = "relu" , kernel_initializer ="he_uniform"))
model.add(MaxPool2D())

model.add(Flatten())

# hidden layers 1
model.add(Dense(128 , activation = "relu" ))
model.add(Dropout(0.4))

# hidden layers 2
model.add(Dense(128 , activation = "relu" ))
model.add(Dropout(0.5))

# hidden layers 3
model.add(Dense(128 , activation = "relu" ))
model.add(Dropout(0.2))

# output
# hidden layers
model.add(Dense(128 , activation = "softmax" ))

model.compile("adam" , loss="sparse_categorical_crossentropy" , metrics=["accuracy"])

history = model.fit(X_train , y_train , epochs = 50 , batch_size=32 , validation_data = (X_test , y_test))

model.evaluate(X_test , y_test)

print(history.history)

print(history.history.keys())

# plotting the graph

plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
plt.title("Model accuracy")
plt.xlabel("epochs")
plt.ylabel("Accuracy")
plt.legend(["train" , "test"])
plt.show

plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])
plt.title("Model loss")
plt.xlabel("epochs")
plt.ylabel("Accuracy")
plt.legend(["train" , "test"])
plt.show

